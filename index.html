<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Van Tran ‚Äî Portfolio</title>
  <meta name="description" content="Portfolio of Van Tran: projects, experience, and contact." />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <div class="container">
      <nav>
        <a class="logo" href="#about">Van Tran</a>
        <div class="links">
          <a href="#about" class="active">About</a>
          <a href="#projects">Projects</a>
          <a href="#experience">Experience</a>
          <a href="#contact">Contact</a>
        </div>
      </nav>
    </div>
  </header>

  <main class="container">
    <section id="about">
      <div class="about-wrap">
        <div>
          <h1>Van Tran</h1>
          <p class="meta" style="margin:6px 0 14px">Aspiring Control & Autonomous Systems Engineer</p>

          <div class="card">
            <h2>Summary</h2>
            <p>
              I‚Äôve been building robots since elementary school, starting with LEGO Mindstorms at LakeLand Elementary.
              In high school, I revived and led FTC Team 8114 as President after it had been inactive for years, and now in college,
              I‚Äôm continuing that same passion through AIAA Comet Aerobotics and academic research.
              I‚Äôm a Computer Engineering student at UT Dallas (‚Äô27) focused on embedded systems, control, and robotics ‚Äî
              designing everything from EMG-controlled prosthetics to autonomous UAVs and lunar rovers.
            </p>
          </div>

          <div class="card">
            <h2>Education</h2>
            <p><strong>University of Texas at Dallas</strong><br>
            B.S. in Computer Engineering ‚Ä¢ Expected May 2027<br>
            GPA: 3.2 ‚Ä¢ UTD Top 10% Scholarship</p>
            <p><strong>Key Coursework:</strong> Embedded Systems, Control Systems, Computer Architecture, Digital Logic, Data Structures & Algorithms.<br>
            <strong>Notable Experience:</strong> Electrical Lead ‚Äì AIAA Comet Aerobotics (Lunabotics Challenge); Research ‚Äì HBS Lab & RIDE Lab.</p>
          </div>

          <div class="card">
            <h2>Skills</h2>
            <p>Embedded Systems ‚Ä¢ Control & Estimation ‚Ä¢ ROS2 ‚Ä¢ PCB Design (Altium) ‚Ä¢ Python/C/C++ ‚Ä¢ MATLAB/Simulink ‚Ä¢ Oscilloscope & Logic Debugging</p>
          </div>
        </div>

        <div>
          <div class="pfp" aria-label="avatar" title="Your photo">
            <img src="photo.jpg" alt="Van Tran" onerror="this.outerHTML='üëã'" />
          </div>
        </div>
      </div>
    </section>

    <section id="projects">
      <h2>Projects</h2>
      <article class="card">
        <h3>EMG-Controlled Prosthetic Arm</h3>
        <p>ESP32 + EMG (uMyo) for muscle-based control; analog/digital filtering reduced latency ~25%.</p>
        <div class="triptych">
          <figure><img src="images/EMG_ARM/EMG_ARM_Fist_One.png" alt="One signal from Flexor Carpi"><figcaption>One EMG signal from Flexor Carpi Radialis Muscle</figcaption></figure>
          <figure><img src="images/EMG_ARM/EMG_ARM_Extension_One.png" alt="One signal from Extensor Carpi"><figcaption>One EMG signal from Extensor Carpi Radialis muscle</figcaption></figure>
          <figure><img src="images/EMG_ARM/EMG_ARM_Flexion_One.png" alt="One signal from Brachioradialis"><figcaption>One EMG from Brachioradialis muscle</figcaption></figure>
        </div>
        <div class="triptych">
          <figure><img src="images/EMG_ARM/EMG_ARM_Fist_Three.png" alt="3 EMG Flexor Carpi"><figcaption>Red Line from three EMG sensors indicate the Flexor Carpi signal</figcaption></figure>
          <figure><img src="images/EMG_ARM/EMG_ARM_Extension_Three.png" alt="3 EMG Extensor Carpi"><figcaption>Blue Line from three EMG sensors indicate the Extensor Carpi signal</figcaption></figure>
          <figure><img src="images/EMG_ARM/EMG_ARM_Flexion_Three.png" alt="3 EMG Brachioradialis"><figcaption>Green Line from three EMG sensors indicate the Brachioradialis signal</figcaption></figure>
        </div>
        <div class="triptych">
          <figure><img src="images/EMG_ARM/EMG_ARM_ESP32_Motor.png" alt="ESP32 with Motor Driver"><figcaption>ESP32 Feather V2 controller with Motor Driver and One Servo (Plan on using 5 stronger servos)</figcaption></figure>
          <figure><img src="images/EMG_ARM/EMG_ARM_Ultimate_Robotics_Arm.jpg" alt="Inspiration"><figcaption>Robotic Arm Inspiration</figcaption></figure>
          <figure><img src="images/EMG_ARM/EMG_ARM_Print_Model.png" alt="Arm Print Model"><figcaption>Model for Robotic Arm</figcaption></figure>
        </div>
      </article>
      <article class="card">
        <h3>Probabilistic UAV Trajectory Prediction</h3>
        <p>
          A 3D aerospace simulation combining
          <strong>classical control theory</strong> with
          <strong>modern diffusion models</strong>.
        </p>
        <p>
          It uses a diffusion-based denoiser to stabilize nonlinear sensor noise before EKF fusion,
          enabling robust target tracking and guidance.
        </p>
        <ul>
          <li><strong>Tracker:</strong> UAV tracking a moving ground object (like a race car)</li>
          <li><strong>Follow:</strong> Rocket pursuit using PD guidance</li>
          <li><strong>Intercept:</strong> Defensive rocket intercept using Proportional Navigation (PN)</li>
        </ul>
        <p>
          Real-time <strong>3D</strong> and <strong>2D visualizations</strong> show how diffusion improves estimation accuracy and stability.
        </p>
        <div class="triptych">
          <figure><img src="images/UAV_Diffusion/UAV_Diff_T1.png" alt="Tracker Graph 1"><figcaption>3D (angle A): UAV (green) flying a quarter-circle arc while tracking a ground target (blue). Diffusion-EKF estimate (orange) stays aligned.</figcaption></figure>
          <figure><img src="images/UAV_Diffusion/UAV_Diff_T2.png" alt="Tracker Graph 2"><figcaption>3D (angle B): Alternate angle highlighting stability through the turn.</figcaption></figure>
          <figure><img src="images/UAV_Diffusion/UAV_Diff_T_Chart.png" alt="Tracker Graph 3"><figcaption>2D Metrics: Position/velocity errors and NEES show bounded estimation.</figcaption></figure>
        </div>
        <div class="triptych">
          <figure><img src="images/UAV_Diffusion/UAV_Diff_F1.png" alt="Follower Graph 1"><figcaption>3D (angle A): Pursuer (green) following target (blue) with smooth PD turns via diffusion-stabilized EKF (orange).</figcaption></figure>
          <figure><img src="images/UAV_Diffusion/UAV_Diff_F2.png" alt="Follower Graph 2"><figcaption>3D (angle B): Alternate perspective showing steady convergence.</figcaption></figure>
          <figure><img src="images/UAV_Diffusion/UAV_Diff_F_Chart.png" alt="Follower Graph 3"><figcaption>2D Metrics: Range decreases, closing speed stabilizes, accel bounded.</figcaption></figure>
        </div>
        <div class="triptych">
          <figure><img src="images/UAV_Diffusion/UAV_Diff_I1.png" alt="Intercepter Graph 1"><figcaption>3D (angle A): Launch-on-close intercept ‚Äî our rocket (green) leads target (blue); orange EKF matches true path.</figcaption></figure>
          <figure><img src="images/UAV_Diffusion/UAV_Diff_I2.png" alt="Intercepter Graph 2"><figcaption>3D (angle B): Rotated view showing intercept point where green meets blue.</figcaption></figure>
          <figure><img src="images/UAV_Diffusion/UAV_Diff_I_Chart.png" alt="Intercepter Graph 3"><figcaption>2D Metrics: Range-to-go drops sharply; closing speed flips near impact.t</figcaption></figure>
        </div>
      </article>
      <article class="card">
        <h3>ROS2 Multi-Drone Coordination</h3>
        <p>I built a three-agent, leader‚Äìfollower swarm that holds single-file formation in Gazebo. 
          First, a kinematic version drives agents via /world/empty/set_pose with a PD controller and soft repulsion to maintain spacing under injected ‚Äúwind‚Äù disturbances. 
          Then I upgrade to a physics-style model: point-mass dynamics with drag and steady/gusty wind forces, where a force-based PD counters drift; terminal logs show spacing error, wind (N), PD counter-force (N), and velocities as proof of correction. 
          Runs on Ubuntu in Parallels (Apple M2).</p>
        <div class="triptych">
          <figure><img src="images/Multi_Drone_Sim/MDS_Kinematic.png" alt="Kinematic Simulation"><figcaption>Multi-Drone Simulation with simple bias and noise</figcaption></figure>
          <figure><img src="images/Multi_Drone_Sim/MDS_Physics.png" alt="Physics Simulation"><figcaption>Multi-Drone Simulation with Physical Wind simulation</figcaption></figure>
        </div>
      </article>
      <article class="card">
        <h3>Wind-Resistant Face-Follow Drone (Tello EDU)</h3>
        <p>I built a control system for the DJI Tello EDU that tracks a user‚Äôs face, maintains a target distance, and actively compensates for side-winds using optical flow. 
          The drone uses the onboard camera feed to detect and center the user‚Äôs face (controlling yaw and forward/back motion) while a separate optical-flow tracker monitors image drift from lateral winds and issues corrective roll commands. 
          A modular architecture separates perception (face + flow), control (PID loops), and the drone interface, enabling a robust real-time system that holds a stable hover and follows the user under air disruption..</p>
        <div class="triptych">
          <figure><img src="images/TELLO/TELLO_Face_Track.png" alt="TELLO Drone Face Tracking"><figcaption>TELLO EDU using Python Program to track face and adjust based on position</figcaption></figure>
        </div>
      </article>
      <article class="card">
        <h3>Homemade DC Motor (DIY)</h3>
        <p>
          Built a simple DC motor from scratch using a custom wooden contraption to hold a shaft and coil held between two nails. 
          This is powered by an 18V battery from a drill that powers two ends of the brush that when in contact with the contraption generate a magnetic field.
          The motor demonstrates a Lorentz force.
        </p>
        <ul>
          <li><strong>Coil:</strong> 150-turn hand-wound copper wire on a custom wooden form.</li>
          <li><strong>Magnet setup:</strong> Two permanent magnets creating a concentrated field across the rotor gap.</li>
          <li><strong>Power:</strong> 18V DC supply; observed stable spin-up and steady rotation.</li>
        </ul>
        <div class="triptych">
          <figure>
            <img src="images/DC_Motor/DC_Motor_Top.png" alt="Top view of DC motor">
            <figcaption>Top view ‚Äî coil alignment between magnet poles.</figcaption>
          </figure>
          <figure>
            <img src="images/DC_Motor/DC_Motor_Side.png" alt="Side view of DC motor setup">
            <figcaption>Side view ‚Äî handmade wood base with copper coil.</figcaption>
          </figure>
          <figure>
            <video controls preload="metadata" poster="images/DC_Motor_Side.png" style="border-radius:12px;border:1px solid var(--line);width:100%;height:270px;object-fit:cover;">
              <source src="videos/DC_Motor_Video.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <figcaption>Spin test ‚Äî stable rotation at 18 V.</figcaption>
          </figure>
        </div>
      </article>
    </section>

    <section id="experience">
      <h2>Experience</h2>
      <article class="card">
        <h3>Comet Aerobotics (AIAA) ‚Äî NASA Lunabotics</h3>
        <p><strong>Role:</strong> Electrical Team Lead</p>
        <p><strong>Contact:</strong> Ian Meyer [ianhmeyer@gmail.com] [214-400-7752]</p>
        <p>Redesigning the rover‚Äôs electrical architecture to optimize power distribution, system safety, and communication reliability. 
          Integrated ESP32 microcontrollers with CAN transceivers to create a modular control network supporting autonomous navigation. 
          Designing custom PCBs in Altium for power regulation and relay switching, reducing wiring complexity and improving fault tolerance. 
          Collaborated with mechanical and software teams to ensure full subsystem compatibility during the ongoing system power redesign phase.</p>
        <div class="triptych">
          <figure><img src="images/CA/CA_Early_Design.png" alt="Harness"><figcaption>Pre-Season early design</figcaption></figure>
          <figure><img src="images/CA/CA_Model_1.png" alt="CAN"><figcaption>Early Model of the Electrical Box</figcaption></figure>
          <figure><img src="images/CA/CA_Model_2.png" alt="System test"><figcaption>Model 2 of the early Electrical Box with Rover</figcaption></figure>
        </div>
        <div class="triptych">
          <figure><img src="images/CA/CA_Box_25.png" alt="Electrical Box"><figcaption>Current Electrical Box Design</figcaption></figure>
          <figure><img src="images/CA/CA_Early_Schematic.png" alt="Electrical Schematic"><figcaption>Early Schematic of the Electrical Box</figcaption></figure>
          <figure><img src="images/CA/CA_ESP32_CAN_PCB.png" alt="ESP32 and CAN PCB"><figcaption>ESP32 and CAN transceiver PCB created to reduce amount of wires and increase connection strength</figcaption></figure>
        </div>
      </article>
      <article class="card">
        <h3>Humanoid Biorobotics and Smart Systems Lab (HBS Lab)</h3>
        <p><strong>Role:</strong> Research Assistant</p>
        <p><strong>Contact:</strong> Dr. Yonas Tadesse [Yonas.Tadesse@utdallas.edu] [972-883-4556]</p>
        <p>Conducted experimental research on Twisted and Coiled Polymer (TCP) actuators for use in soft robotics and expressive systems. 
          Fabricated TCP samples, performed thermal and pressure-based characterization, and analyzed contraction behavior through MATLAB-based tracking. 
          Designed and tested setups to measure heating/cooling cycles under variable loads, validating actuator performance for two real-world applications: a soft robotic manipulator and an anthropomorphic robotic face capable of producing facial expressions.</p>
        <div class="triptych">
          <figure>
            <video controls preload="metadata" poster="images/HBS/HBS_TCP_Create.png" style="border-radius:12px;border:1px solid var(--line);width:100%;height:270px;object-fit:cover;">
              <source src="videos/Create.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <figcaption>Spinning the cable while holding it to create coils.</figcaption>
          </figure>
          <figure>
            <video controls preload="metadata" poster="images/HBS/HBS_TCP_Train.png" style="border-radius:12px;border:1px solid var(--line);width:100%;height:270px;object-fit:cover;">
              <source src="videos/Train.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <figcaption>Training the TCP with 9V</figcaption>
          </figure>
          <figure><img src="images/HBS/HBS_TCP_Pressure_Test.png" alt="Plot"><figcaption>TCP healing and cooling test under different pressures</figcaption></figure>
        </div>
        <div class="triptych">
          <figure><img src="images/HBS/HBS_TCP_Face.png" alt="TCP Silicone Face"><figcaption>Facial Expressions using TCP under silicone skin mask</figcaption></figure>
          <figure><img src="images/HBS/HBS_TCP_Robot.png" alt="TCP Robot Arm"><figcaption>Robotic Arm developed with TCP muscles</figcaption></figure>
          <figure><img src="images/HBS/HBS_TCP_Limb.png" alt="TCP Soft Limb"><figcaption>Soft Robotic Limb using TCP and silicone</figcaption></figure>
        </div>
      </article>
      <article class="card">
        <h3>Accessible Prosthetics Initiative</h3>
        <p><strong>Role:</strong> Electrical/Embedded Systems Member</p>
        <p><strong>Contact:</strong> Michael Dahl [Michael.Dahl@utdallas.edu] [717-704-9291]</p>
        <p>Developed a 3D-printed, low-cost prosthetic arm powered by an ESP32 microcontroller and controlled using EMG signals. 
          Designed custom actuator mounts and integrated dual buck converters for stable servo operation. 
          Led the integration of uMyo EMG sensors for accurate and responsive user interface, enabling intuitive control of the prosthetic hand movements.
          </p>
        <div class="triptych">
          <figure><img src="images/API/API_Arm_Front.png" alt="Arm Front"><figcaption>Front of Proshetic Arm</figcaption></figure>
          <figure><img src="images/API/API_Arm_Back.png" alt="Arm Back"><figcaption>Back of Prosthetic Arm</figcaption></figure>
          <figure><img src="images/API/API_Arm_Side.png" alt="Arm Side"><figcaption>Side of Prosthetic Arm with ESP32 stack and connectors</figcaption></figure>
        </div>
        <div class="triptych">
          <figure>
            <video controls preload="metadata" poster="images/API/API_Hand_Close_Cover.jpg" style="border-radius:12px;border:1px solid var(--line);width:100%;height:270px;object-fit:cover;">
              <source src="videos/API_Hand_Close.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <figcaption>Demonstrating the Prosthetic Arm running with ESP32 and ArduinoIDE</figcaption>
          </figure>
        </div>
      </article>
      <article class="card">
        <h3>Integrated Biomedical, RF Circuits and Systems Lab (iBioRF)</h3>
        <p><strong>Role:</strong> Research Assistant</p>
        <p><strong>Contact:</strong> Erik Pineda-Alvarez [Erik.Pineda-Alvarez@utdallas.edu]</p>
        <p>Developing wireless drone control systems using the USRP B206mini-i software-defined radio (SDR). 
          Focused on generating and transmitting RF signals for real-time UAV communication and coordination through RadioConda and GNU Radio. 
          Work emphasizes RF signal processing, link stability testing, and integration with embedded control architectures for large-scale autonomous flight.
        </p>
        <div class="triptych">
          <figure><img src="images/iBioRF/iBioRF_SDR.jpg" alt="USRP B206mini-i"><figcaption>USRP B206mini-i SDR</figcaption></figure>
          <figure><img src="images/iBioRF/iBioRF_2_4GHz.png" alt="Generating 2.4Ghz RF Waves"><figcaption>Generating 2.4Ghz RF signals</figcaption></figure>
          <figure><img src="images/iBioRF/iBioRF_Block_Diagram.png" alt="RF Block Diagrams"><figcaption>Block Diagram to generate RF signals</figcaption></figure>
        </div>
      </article>
      <article class="card">
        <h3>EPICS Project</h3>
        <p><strong>Role:</strong> Backend Developer</p>
        <p>Collaborated with a community partner to design and develop a web platform for the Friends of MLK Reading Huddle,
          promoting literacy and mentorship for underserved students. Contributed to full-stack development using Vue.js,
          Tailwind CSS, TypeScript, Docker, and PostgreSQL with Prisma ORM. Focused on building accessible, responsive
          interfaces and a scalable backend to support event scheduling, volunteer management, and resource sharing.
        </p>
        <div class="triptych">
          <figure><img src="images/EPICS/EPICS_GANTT.jpeg" alt="EPICS 1"><figcaption>Project GANTT Chart</figcaption></figure>
          <figure><img src="images/EPICS/EPICS_Andrea.jpg" alt="EPICS 2"><figcaption>Final Presentation with Professor</figcaption></figure>
          <figure><img src="images/EPICS/EPICS_Rae.jpg" alt="EPICS 3"><figcaption>Final Presentation with Friends of MLK sponsor, Rae</figcaption></figure>
        </div>
      </article>
      <article class="card">
        <h3>IEEE Project</h3>
        <p><strong>Role:</strong> Member </p>
        <p>Developed a convolutional neural network (CNN) for dog breed classification as part of an IEEE student
            research project. Implemented data preprocessing, model training, and validation using Python and TensorFlow,
            achieving strong class separation across 10+ breeds. Evaluated performance through a confusion matrix to
            analyze prediction accuracy and misclassification trends.
        </p>
        <div class="triptych">
          <figure><img src="images/IEEE/IEEE_Confusion_Matrix.png" alt="IEEE 1"><figcaption>Confusion matrix showing per-class accuracy for the CNN-based dog breed classifier.
          High diagonal concentration indicates strong model precision across most categories.</figcaption></figure>
        </div>
      </article>
      <article class="card">
        <h3>RIDE Lab ‚Äî Orthotic Design</h3>
        <p><strong>Role:</strong> Team Lead</p>
        <p>Conducting foundational research for a next-generation prosthetic arm aimed at improving accessibility and control for users with partial limb loss. 
          Focused on benchmarking existing prosthetic technologies, analyzing actuator and joint mechanisms, and preparing design proposals for future prototyping phases. 
          Collaborated in team presentations translating technical findings into actionable design plans for future implementation.</p>
      </article>
    </section>

    <section id="contact">
      <h2>Contact</h2>
      <p>Email: <a href="mailto:vtt230000@utdallas.edu">vtt230000@utdallas.edu</a> | <a href="https://linkedin.com/in/vantrn" target="_blank">LinkedIn</a> | <a href="https://github.com/vantrn" target="_blank">GitHub</a></p>
    </section>
  </main>

  <footer>
    <div class="container">
      <p>¬© <span id="year"></span> Van Tran</p>
    </div>
  </footer>

  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
    document.querySelectorAll('a[href^="#"]').forEach(a=>{
      a.addEventListener('click',e=>{
        const id=a.getAttribute('href').slice(1);
        const el=document.getElementById(id);
        if(el){e.preventDefault();document.querySelectorAll('.links a').forEach(x=>x.classList.remove('active'));a.classList.add('active');el.scrollIntoView({behavior:'smooth', block:'start'});}
      });
    });
  </script>
</body>
</html>
